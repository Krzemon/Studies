{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8971a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import bib\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from skimage.transform import hough_line, hough_line_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4890899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 55\u001b[0m\n\u001b[0;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     51\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Funkcja straty dla klasyfikacji binarnej\u001b[39;00m\n\u001b[0;32m     52\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Trenowanie modelu\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:1754\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1752\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1754\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected result of `train_function` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1756\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Empty logs). This could be due to issues in input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1757\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline that resulted in an empty dataset. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1758\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1759\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation of where went wrong, or file a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1762\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1763\u001b[0m     )\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_get_metrics_result(logs)\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "# Ścieżki do folderów z obrazami i etykietami\n",
    "folder_tak_images = \"razem\"  # Zmień na właściwą ścieżkę\n",
    "\n",
    "# Funkcja do wczytywania i przetwarzania obrazów\n",
    "def load_and_process_image(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_image(img, channels=1)  # Odcienie szarości\n",
    "    img = tf.image.resize(img, (180, 180))  # Dopasowanie do ustalonego rozmiaru\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)  # Konwersja do float32\n",
    "    return img\n",
    "\n",
    "# Wczytanie obrazów i etykiet\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "# Wczytaj obrazy i etykiety z foldera \"razem\"\n",
    "for filename in os.listdir(folder_tak_images):\n",
    "    if filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(folder_tak_images, filename)\n",
    "        label_path = os.path.splitext(image_path)[0] + \".txt\"\n",
    "        if os.path.exists(label_path):\n",
    "            image = load_and_process_image(image_path)\n",
    "            with open(label_path, 'r') as label_file:\n",
    "                label = int(label_file.read())\n",
    "            all_images.append(image)\n",
    "            all_labels.append(label)\n",
    "\n",
    "# Połączenie danych\n",
    "all_images = np.array(all_images)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Przygotowanie datasetu\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_images, all_labels))\n",
    "\n",
    "# Wymieszanie i podzielenie datasetu na zbiór treningowy i walidacyjny\n",
    "buffer_size = 1000  # Wartość większa niż zero\n",
    "dataset = dataset.shuffle(buffer_size=buffer_size).batch(128)\n",
    "train_size = int(0.8 * len(all_images))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "# Definicja modelu\n",
    "model = keras.Sequential([\n",
    "    layers.Flatten(input_shape=(180, 180)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Model klasyfikacji binarnej\n",
    "])\n",
    "\n",
    "# Kompilacja modelu\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Funkcja straty dla klasyfikacji binarnej\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trenowanie modelu\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_path):\n",
    "    # Wczytaj obraz w skali szarości i przeskaluj\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (180, 180))\n",
    "    image = image / 255.0\n",
    "\n",
    "    # Przygotuj obraz do przewidywania\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Wczytaj model klasyfikatora\n",
    "#model = tf.keras.models.load_model(\"model_klasyfikatora.h5\")\n",
    "\n",
    "# Ścieżka do nowego obrazu\n",
    "new_image_path = 'fields.jpg'\n",
    "\n",
    "# Wczytaj i przetwórz nowy obraz\n",
    "new_image = process_image(new_image_path)\n",
    "\n",
    "# Wykonaj predykcję\n",
    "prediction = model.predict(new_image)\n",
    "\n",
    "# Interpretuj wynik\n",
    "if prediction[0][0] >= 0.9:\n",
    "    print(\"Na obrazie na ponad 90% jest zarejestrowana działalność ludzka.\")\n",
    "else:\n",
    "    print(\"Na obrazie brak jest działalności ludzkiej.\")\n",
    "\n",
    "original_image = cv2.imread(new_image_path)\n",
    "original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Wyświetl oryginalny obraz\n",
    "plt.imshow(original_image_rgb)\n",
    "plt.axis('off')  # Wyłącz osie\n",
    "plt.show()\n",
    "print(prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9b72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import bib\n",
    "import cv2\n",
    "\n",
    "# Funkcja do zapisu obrazu jako pliku\n",
    "def save_image(image, file_path):\n",
    "    image = image * 255.0  # Przywróć zakres pikseli do 0-255\n",
    "    image = image.astype(np.uint8)  # Konwertuj na typ uint8\n",
    "    cv2.imwrite(file_path, image)  # Zapisz obraz\n",
    "\n",
    "# Wykonaj transformację Furiera na obrazie\n",
    "input_path = 'bajojajo.webp'\n",
    "widmo_amp = bib.Furia(input_path)\n",
    "\n",
    "# Zapisz widmo_amp jako plik obrazu (np. PNG)\n",
    "output_path = 'widmo_amp.png'\n",
    "save_image(widmo_amp, output_path)\n",
    "\n",
    "# Przetwórz zapisane widmo_amp jako plik wejściowy\n",
    "new_image = process_image(output_path)\n",
    "prediction2 = model.predict(new_image)\n",
    "\n",
    "# Interpretuj wynik\n",
    "if prediction2[0][0] >= 0.9:\n",
    "    print(\"Na obrazie na ponad 90% jest zarejestrowana działalność ludzka.\")\n",
    "else:\n",
    "    print(\"Na obrazie brak jest działalności ludzkiej.\")\n",
    "    \n",
    "print(prediction2[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756fe3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd10bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
